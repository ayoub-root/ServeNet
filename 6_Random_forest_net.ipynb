{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pandas import read_hdf, concat\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type2idx(Data_c,Type_c):\n",
    "    n_samples=len(Data_c)\n",
    "    target = np.empty((n_samples,), dtype=np.int)\n",
    "    for idx in range(n_samples):\n",
    "        if Data_c[idx] in Type_c:\n",
    "            target[idx]=Type_c.index(Data_c[idx])\n",
    "        else:\n",
    "            target[idx] = -1\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'D:\\python_projects\\ServeNet_others\\data\\\\ramdom_categorg_percent\\RandomSplittedByCatagories9.h5'\n",
    "TrainServices = read_hdf(url, key='Train')\n",
    "TestServices = read_hdf(url, key='Test')\n",
    "AllData = concat([TrainServices, TestServices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = list(TrainServices['Service Desciption'])\n",
    "target_train = list(TrainServices['Service Classification'])\n",
    "data_test = list(TestServices['Service Desciption'])\n",
    "target_test = list(TestServices['Service Classification'])\n",
    "\n",
    "X_train = data_train\n",
    "Y_train = target_train\n",
    "X_test = data_test\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_c = (list(np.unique(target_train)))\n",
    "# Type_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=1500, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n        stop_words='english', strip_accents=None, sublinear_tf=True,\n        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n        vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 1500\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english', max_features=max_features)\n",
    "tfidf_vectorizer.fit(list(AllData['Service Desciption']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_vectorizer.transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  36.77560567855835\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=40, random_state=0)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(X_train, Y_train)\n",
    "t1 = time()\n",
    "print(\"Train time: \", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_top5 = clf.predict_proba(X_train)\n",
    "train_top1 = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top5 = clf.predict_proba(X_test)\n",
    "test_top1 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\nTest top5 acc:0.800,  Train top5 acc:0.955\nTest top1 acc:0.541,  Train top1 acc:0.835\nF1_score:0.800\n============================================================\n"
     ]
    }
   ],
   "source": [
    "test_ret = np.empty((len(Y_test),), dtype=np.int)\n",
    "train_ret = np.empty((len(Y_train),), dtype=np.int)\n",
    "\n",
    "# test top-5 accuracy\n",
    "for i in range(len(Y_test)):\n",
    "    Top5_test = sorted(zip(clf.classes_, test_top5[i]), key=lambda x: x[1])[-5:]\n",
    "    Top5_test = list(map(lambda x: x[0], Top5_test))\n",
    "    \n",
    "    if Y_test[i] in Top5_test:\n",
    "        test_ret[i] = Y_test[i]\n",
    "    else:\n",
    "        test_ret[i] = Top5_test[-1]\n",
    "\n",
    "# train top-5 accuracy\n",
    "for i in range(len(Y_train)):\n",
    "    Top5_train = sorted(zip(clf.classes_, train_top5[i]), key=lambda x: x[1])[-5:]\n",
    "    Top5_train = list(map(lambda x: x[0], Top5_train))\n",
    "    \n",
    "    if Y_train[i] in Top5_train:\n",
    "        train_ret[i] = Y_train[i]\n",
    "    else:\n",
    "        train_ret[i] = Top5_train[-1]\n",
    "\n",
    "f1_s = f1_score(Y_test, test_ret, average='micro')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Test top5 acc:%.3f,  Train top5 acc:%.3f\" % (accuracy_score(Y_test, test_ret), accuracy_score(Y_train, train_ret)))\n",
    "print(\"Test top1 acc:%.3f,  Train top1 acc:%.3f\" % (accuracy_score(Y_test, test_top1),\n",
    "                                               accuracy_score(Y_train, train_top1)))\n",
    "print(\"F1_score:%.3f\" % float(f1_s))\n",
    "print(\"=\" * 60)\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_c_index = type2idx(Type_c, Type_c)\n",
    "result_dict = {}\n",
    "total_dict = {}\n",
    "for idx in type_c_index:\n",
    "    category = Type_c[idx]\n",
    "    total_count = 0\n",
    "    account = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_test[i] == idx:\n",
    "            total_count += 1\n",
    "            if Y_test[i] == test_ret[i]:\n",
    "                account += 1\n",
    "\n",
    "    result_dict[category] = account / total_count * 1.\n",
    "    total_dict[category] = total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertising (42): 0.857\nAnalytics (23): 0.348\nApplication Development (23): 0.087\nBackend (27): 0.333\nBanking (20): 0.850\nBitcoin (28): 0.964\nChat (16): 0.688\nCloud (33): 0.909\nData (28): 0.143\nDatabase (27): 0.185\nDomains (16): 0.750\nEducation (41): 0.854\nEmail (48): 0.917\nEnterprise (79): 0.924\nEntertainment (19): 0.105\nEvents (21): 0.905\nFile Sharing (16): 0.688\nFinancial (130): 1.000\nGames (39): 0.897\nGovernment (55): 0.764\nImages (15): 0.467\nInternet of Things (22): 0.636\nMapping (67): 0.910\nMarketing (16): 0.750\nMedia (16): 0.250\nMedical (21): 0.714\nMessaging (97): 0.969\nMusic (37): 0.892\nNews Services (16): 0.500\nOther (29): 0.034\nPayments (85): 0.918\nPhotos (35): 0.886\nProject Management (28): 0.786\nReal Estate (21): 0.857\nReference (47): 0.362\nScience (55): 0.909\nSearch (43): 0.651\nSecurity (47): 0.468\nShipping (26): 0.962\nSocial (80): 0.938\nSports (43): 0.791\nStocks (19): 0.947\nStorage (19): 0.632\nTelephony (57): 0.842\nTools (146): 1.000\nTransportation (42): 0.833\nTravel (45): 0.822\nVideo (47): 0.979\nWeather (23): 0.957\neCommerce (86): 0.965\n"
     ]
    }
   ],
   "source": [
    "for cate in result_dict.keys():\n",
    "    total_account = total_dict[cate]\n",
    "    acc = result_dict[cate]\n",
    "    print(\"%s (%d): %.3f\" % (cate, total_account, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
