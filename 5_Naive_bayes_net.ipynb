{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pandas import read_hdf, concat\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def type2idx(Data_c,Type_c):\n",
    "    n_samples=len(Data_c)\n",
    "    target = np.empty((n_samples,), dtype=np.int)\n",
    "    for idx in range(n_samples):\n",
    "        if Data_c[idx] in Type_c:\n",
    "            target[idx]=Type_c.index(Data_c[idx])\n",
    "        else:\n",
    "            target[idx] = -1\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'D:\\python_projects\\ServeNet_others\\data\\\\ramdom_categorg_percent\\RandomSplittedByCatagories9.h5'\n",
    "TrainServices = read_hdf(url, key='Train')\n",
    "TestServices = read_hdf(url, key='Test')\n",
    "AllData = concat([TrainServices, TestServices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = list(TrainServices['Service Desciption'])\n",
    "target_train = list(TrainServices['Service Classification'])\n",
    "data_test = list(TestServices['Service Desciption'])\n",
    "target_test = list(TestServices['Service Classification'])\n",
    "\n",
    "X_train = data_train\n",
    "Y_train = target_train\n",
    "X_test = data_test\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_c = (list(np.unique(target_train)))\n",
    "# Type_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.fit_transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=1500, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n        stop_words='english', strip_accents=None, sublinear_tf=True,\n        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n        vocabulary=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 1500\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english', max_features=max_features)\n",
    "tfidf_vectorizer.fit(list(AllData['Service Desciption']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_vectorizer.transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.017496585845947266\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(X_train, Y_train)\n",
    "t1 = time()\n",
    "print('Training time: ', (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_top5 = clf.predict_proba(X_train)\n",
    "train_top1 = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top5 = clf.predict_proba(X_test)\n",
    "test_top1 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\nTest top5 acc:0.757,  Train top5 acc:0.841\nTest top1 acc:0.472,  Train top1 acc:0.560\nF1_score:0.757\n============================================================\n"
     ]
    }
   ],
   "source": [
    "test_ret = np.empty((len(Y_test),), dtype=np.int)\n",
    "train_ret = np.empty((len(Y_train),), dtype=np.int)\n",
    "\n",
    "# test top-5 accuracy\n",
    "for i in range(len(Y_test)):\n",
    "    Top5_test = sorted(zip(clf.classes_, test_top5[i]), key=lambda x: x[1])[-5:]\n",
    "    Top5_test = list(map(lambda x: x[0], Top5_test))\n",
    "    \n",
    "    if Y_test[i] in Top5_test:\n",
    "        test_ret[i] = Y_test[i]\n",
    "    else:\n",
    "        test_ret[i] = Top5_test[-1]\n",
    "\n",
    "# train top-5 accuracy\n",
    "for i in range(len(Y_train)):\n",
    "    Top5_train = sorted(zip(clf.classes_, train_top5[i]), key=lambda x: x[1])[-5:]\n",
    "    Top5_train = list(map(lambda x: x[0], Top5_train))\n",
    "    \n",
    "    if Y_train[i] in Top5_train:\n",
    "        train_ret[i] = Y_train[i]\n",
    "    else:\n",
    "        train_ret[i] = Top5_train[-1]\n",
    "\n",
    "f1_s = f1_score(Y_test, test_ret, average='micro')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Test top5 acc:%.3f,  Train top5 acc:%.3f\" % (accuracy_score(Y_test, test_ret), accuracy_score(Y_train, train_ret)))\n",
    "print(\"Test top1 acc:%.3f,  Train top1 acc:%.3f\" % (accuracy_score(Y_test, test_top1),\n",
    "                                               accuracy_score(Y_train, train_top1)))\n",
    "print(\"F1_score:%.3f\" % float(f1_s))\n",
    "print(\"=\" * 60)\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_c_index = type2idx(Type_c, Type_c)\n",
    "result_dict = {}\n",
    "total_dict = {}\n",
    "for idx in type_c_index:\n",
    "    category = Type_c[idx]\n",
    "    total_count = 0\n",
    "    account = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_test[i] == idx:\n",
    "            total_count += 1\n",
    "            if Y_test[i] == test_ret[i]:\n",
    "                account += 1\n",
    "\n",
    "    result_dict[category] = account / total_count * 1.\n",
    "    total_dict[category] = total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertising (42): 0.786\nAnalytics (23): 0.000\nApplication Development (23): 0.130\nBackend (27): 0.148\nBanking (20): 0.400\nBitcoin (28): 0.821\nChat (16): 0.062\nCloud (33): 0.576\nData (28): 0.143\nDatabase (27): 0.111\nDomains (16): 0.625\nEducation (41): 0.805\nEmail (48): 0.896\nEnterprise (79): 0.987\nEntertainment (19): 0.158\nEvents (21): 0.333\nFile Sharing (16): 0.438\nFinancial (130): 0.992\nGames (39): 0.795\nGovernment (55): 0.945\nImages (15): 0.000\nInternet of Things (22): 0.500\nMapping (67): 0.970\nMarketing (16): 0.000\nMedia (16): 0.000\nMedical (21): 0.143\nMessaging (97): 1.000\nMusic (37): 0.811\nNews Services (16): 0.250\nOther (29): 0.000\nPayments (85): 0.988\nPhotos (35): 0.714\nProject Management (28): 0.750\nReal Estate (21): 0.524\nReference (47): 0.617\nScience (55): 0.891\nSearch (43): 0.767\nSecurity (47): 0.638\nShipping (26): 0.731\nSocial (80): 0.988\nSports (43): 0.837\nStocks (19): 0.947\nStorage (19): 0.105\nTelephony (57): 0.982\nTools (146): 0.993\nTransportation (42): 0.857\nTravel (45): 0.867\nVideo (47): 0.936\nWeather (23): 0.870\neCommerce (86): 0.965\n"
     ]
    }
   ],
   "source": [
    "for cate in result_dict.keys():\n",
    "    total_account = total_dict[cate]\n",
    "    acc = result_dict[cate]\n",
    "    print(\"%s (%d): %.3f\" % (cate, total_account, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
